{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Comprehensive D&D Model Training Notebook\n",
				"\n",
				"This notebook provides an interactive interface for training custom D&D models.\n",
				"\n",
				"## Features\n",
				"- Automated Environment Setup\n",
				"- Data Analysis and Visualization\n",
				"- Interactive Training Configuration\n",
				"- Model Training and Validation\n",
				"- GGUF Export for CactusTTS\n",
				"- Complete Pipeline Automation"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Setup and imports\n",
				"import sys\n",
				"import os\n",
				"import json\n",
				"from pathlib import Path\n",
				"from datetime import datetime\n",
				"\n",
				"# Add parent directory for imports\n",
				"sys.path.append('..')\n",
				"\n",
				"print(\"ğŸš€ Notebook environment initialized\")\n",
				"print(f\"ğŸ“ Working directory: {os.getcwd()}\")\n",
				"print(f\"ğŸ Python version: {sys.version}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Environment validation\n",
				"def check_environment():\n",
				"    \"\"\"Check if environment is ready for training.\"\"\"\n",
				"    results = {'pytorch': False, 'transformers': False, 'gpu_available': False}\n",
				"    \n",
				"    try:\n",
				"        import torch\n",
				"        results['pytorch'] = True\n",
				"        print(f\"âœ… PyTorch {torch.__version__} detected\")\n",
				"        \n",
				"        if torch.cuda.is_available():\n",
				"            results['gpu_available'] = True\n",
				"            print(f\"âœ… CUDA GPU: {torch.cuda.get_device_name()}\")\n",
				"        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
				"            results['gpu_available'] = True\n",
				"            print(\"âœ… Apple Silicon GPU available\")\n",
				"        else:\n",
				"            print(\"âš ï¸  CPU training (slower)\")\n",
				"    except ImportError:\n",
				"        print(\"âŒ PyTorch not found\")\n",
				"    \n",
				"    try:\n",
				"        import transformers\n",
				"        results['transformers'] = True\n",
				"        print(f\"âœ… Transformers {transformers.__version__}\")\n",
				"    except ImportError:\n",
				"        print(\"âŒ Transformers not found\")\n",
				"    \n",
				"    return results\n",
				"\n",
				"env_status = check_environment()\n",
				"print(f\"\\nğŸ“Š Environment Status: {sum(env_status.values())}/{len(env_status)} checks passed\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Training data analysis\n",
				"def analyze_training_data():\n",
				"    \"\"\"Analyze training data structure.\"\"\"\n",
				"    data_dir = Path(\"../data/scenarios\")\n",
				"    \n",
				"    if not data_dir.exists():\n",
				"        print(\"âŒ No training data directory found\")\n",
				"        return None\n",
				"    \n",
				"    md_files = list(data_dir.rglob(\"*.md\"))\n",
				"    print(f\"ğŸ“– Found {len(md_files)} training files\")\n",
				"    \n",
				"    analysis = {\n",
				"        'total_files': len(md_files),\n",
				"        'categories': {},\n",
				"        'tool_calls': {},\n",
				"        'conversations': 0\n",
				"    }\n",
				"    \n",
				"    import re\n",
				"    tool_pattern = r'\\[([a-zA-Z_][a-zA-Z0-9_]*)\\s*:\\s*([^\\]]+)\\]'\n",
				"    \n",
				"    for md_file in md_files:\n",
				"        category = md_file.parent.name\n",
				"        analysis['categories'][category] = analysis['categories'].get(category, 0) + 1\n",
				"        \n",
				"        try:\n",
				"            with open(md_file, 'r', encoding='utf-8') as f:\n",
				"                content = f.read()\n",
				"            \n",
				"            sections = content.split('\\n# ')\n",
				"            analysis['conversations'] += max(0, len(sections) - 1)\n",
				"            \n",
				"            tool_matches = re.findall(tool_pattern, content)\n",
				"            for tool_name, args in tool_matches:\n",
				"                tool_name = tool_name.lower()\n",
				"                analysis['tool_calls'][tool_name] = analysis['tool_calls'].get(tool_name, 0) + 1\n",
				"                \n",
				"        except Exception as e:\n",
				"            print(f\"âš ï¸  Error analyzing {md_file}: {e}\")\n",
				"    \n",
				"    return analysis\n",
				"\n",
				"data_analysis = analyze_training_data()\n",
				"\n",
				"if data_analysis:\n",
				"    print(f\"\\nğŸ“Š Training Data Analysis:\")\n",
				"    print(f\"  ğŸ“ Total files: {data_analysis['total_files']}\")\n",
				"    print(f\"  ğŸ’¬ Conversations: {data_analysis['conversations']}\")\n",
				"    print(f\"  ğŸ”§ Unique tools: {len(data_analysis['tool_calls'])}\")\n",
				"    \n",
				"    print(f\"\\nğŸ“‚ Categories:\")\n",
				"    for category, count in data_analysis['categories'].items():\n",
				"        print(f\"  - {category}: {count} files\")\n",
				"    \n",
				"    print(f\"\\nğŸ”§ Top Tools:\")\n",
				"    top_tools = sorted(data_analysis['tool_calls'].items(), key=lambda x: x[1], reverse=True)[:5]\n",
				"    for tool, count in top_tools:\n",
				"        print(f\"  - {tool}: {count} uses\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Model training function\n",
				"def run_training(mode='full', learning_rate=2e-4, max_steps=60):\n",
				"    \"\"\"Execute model training.\"\"\"\n",
				"    from train_dnd_model_v2 import DNDModelTrainer\n",
				"    \n",
				"    trainer = DNDModelTrainer()\n",
				"    trainer.incremental_mode = (mode == 'incremental')\n",
				"    trainer.learning_rate = learning_rate\n",
				"    trainer.max_steps = max_steps\n",
				"    \n",
				"    if trainer.incremental_mode:\n",
				"        trainer.base_model_path = './trained_models/dnd_model'\n",
				"        print(f\"ğŸ”„ Incremental training mode\")\n",
				"    else:\n",
				"        print(f\"ğŸ†• Full training mode\")\n",
				"    \n",
				"    print(f\"âš™ï¸  Configuration:\")\n",
				"    print(f\"  ğŸ“Š Learning rate: {trainer.learning_rate}\")\n",
				"    print(f\"  ğŸ”¢ Max steps: {trainer.max_steps}\")\n",
				"    \n",
				"    start_time = datetime.now()\n",
				"    print(f\"\\nğŸš€ Starting training at {start_time.strftime('%H:%M:%S')}...\")\n",
				"    \n",
				"    success = trainer.train()\n",
				"    \n",
				"    end_time = datetime.now()\n",
				"    duration = end_time - start_time\n",
				"    \n",
				"    if success:\n",
				"        print(f\"\\nâœ… Training completed successfully in {duration}\")\n",
				"    else:\n",
				"        print(f\"\\nâŒ Training failed after {duration}\")\n",
				"    \n",
				"    return success\n",
				"\n",
				"print(\"ğŸ‹ï¸â€â™‚ï¸ Training function ready\")\n",
				"print(\"Use: run_training(mode='full', learning_rate=2e-4, max_steps=60)\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Tool extension\n",
				"def extend_tools():\n",
				"    \"\"\"Extend tool vocabulary.\"\"\"\n",
				"    from tool_extension_framework import ToolExtensionFramework\n",
				"    \n",
				"    framework = ToolExtensionFramework(\"../data\", \"../trained_models\")\n",
				"    success = framework.run_tool_extension(auto_approve=True)\n",
				"    \n",
				"    if success:\n",
				"        print(\"âœ… Tool vocabulary extended!\")\n",
				"    else:\n",
				"        print(\"âŒ Tool extension failed\")\n",
				"    \n",
				"    return success\n",
				"\n",
				"print(\"ğŸ”§ Tool extension function ready\")\n",
				"print(\"Use: extend_tools()\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# Complete pipeline\n",
				"def run_complete_pipeline():\n",
				"    \"\"\"Run the complete training pipeline.\"\"\"\n",
				"    print(\"ğŸš€ Starting Complete Training Pipeline\")\n",
				"    print(\"=\" * 50)\n",
				"    \n",
				"    steps = [\n",
				"        (\"ğŸ”§ Tool Extension\", extend_tools),\n",
				"        (\"ğŸ‹ï¸â€â™‚ï¸ Model Training\", lambda: run_training()),\n",
				"    ]\n",
				"    \n",
				"    results = {}\n",
				"    \n",
				"    for step_name, step_func in steps:\n",
				"        print(f\"\\n{step_name}...\")\n",
				"        try:\n",
				"            success = step_func()\n",
				"            results[step_name] = success\n",
				"            if success:\n",
				"                print(f\"âœ… {step_name} completed\")\n",
				"            else:\n",
				"                print(f\"âŒ {step_name} failed\")\n",
				"                break\n",
				"        except Exception as e:\n",
				"            print(f\"âŒ {step_name} error: {e}\")\n",
				"            results[step_name] = False\n",
				"            break\n",
				"    \n",
				"    print(\"\\n\" + \"=\" * 60)\n",
				"    print(\"ğŸ‰ PIPELINE COMPLETED!\")\n",
				"    print(\"=\" * 60)\n",
				"    \n",
				"    for step_name, success in results.items():\n",
				"        status = \"âœ…\" if success else \"âŒ\"\n",
				"        print(f\"{status} {step_name}\")\n",
				"    \n",
				"    all_success = all(results.values())\n",
				"    if all_success:\n",
				"        print(\"\\nğŸŠ All steps completed successfully!\")\n",
				"        print(\"Your D&D model is ready for CactusTTS integration!\")\n",
				"    else:\n",
				"        print(\"\\nâš ï¸  Some steps failed. Check the output above.\")\n",
				"    \n",
				"    return all_success\n",
				"\n",
				"print(\"ğŸ¯ Complete pipeline function ready\")\n",
				"print(\"Use: run_complete_pipeline()\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Usage Examples\n",
				"\n",
				"### Quick Start\n",
				"```python\n",
				"# Run complete pipeline\n",
				"run_complete_pipeline()\n",
				"```\n",
				"\n",
				"### Individual Steps\n",
				"```python\n",
				"# Extend tools\n",
				"extend_tools()\n",
				"\n",
				"# Train model\n",
				"run_training(mode='full', learning_rate=2e-4, max_steps=60)\n",
				"\n",
				"# Incremental training\n",
				"run_training(mode='incremental', learning_rate=1e-6, max_steps=20)\n",
				"```\n",
				"\n",
				"### Integration\n",
				"After training, your model will be available at:\n",
				"- **Model**: `./trained_models/dnd_model/`\n",
				"- **Config**: `./trained_models/dnd_model/cactus_config.json`\n",
				"- **Tools**: `./trained_models/tool_registry.json`"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.0"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}