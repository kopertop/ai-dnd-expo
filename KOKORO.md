# KOKORO ‚Äì On‚Äëdevice TTS integration (MLX‚ÄØKokoro‚Äë82M)

## ‚úÖ Goal
Add **on‚Äëdevice text‚Äëto‚Äëspeech** for iOS by loading the community‚Äëconverted MLX checkpoint of the Kokoro‚Äë82M model (`mlx-community/Kokoro-82M-bf16`).
The implementation uses:
- **MLX‚ÄëSwift** for inference on Apple Silicon.
- **Expo‚Äëmodules** native bridge to expose a `synthesize(text, voice)` function to JavaScript.
- A **shell script** (`download_kokoro.sh`) that clones the HF repo (Git‚ÄëLFS) and copies `kokoro.mlx` + `tokenizer.json` into the iOS resources folder.
- A **TypeScript provider** (`services/ai/providers/kokoro.ts`) that conforms to the existing TTS interface.
- A **settings toggle** so users can enable/disable on‚Äëdevice TTS.
- Unit and integration tests plus CI support.

---

## üìÇ Repository changes
| Path | Type | Reason |
|------|------|--------|
| `scripts/download_kokoro.sh` | Shell script | Clone the Hugging‚ÄØFace repo and place the model files in `ios/KokoroTTS/Resources`. |
| `ios/KokoroTTS/` | Swift target (new) | Contains `KokoroTTSModule.swift` (Expo bridge) and `KokoroInference.swift` (MLX inference). |
| `services/ai/providers/kokoro.ts` | TS | JS wrapper that calls the native module. |
| `hooks/use-text-to-speech.ts` | TS | Adds `LocalKokoro` enum/value and a selector function. |
| `components/settings-view.tsx` (optional) | TSX | UI switch **‚ÄúUse on‚Äëdevice speech (iOS only)‚Äù** that toggles a flag in the settings store. |
| `tests/unit/components/kokoro-tts.test.tsx` | TSX | Unit test with a mocked native module. |
| `tests/e2e/kokoro-tts.e2e.test.ts` | TSX | Real iOS‚Äësimulator test that synthesises and plays a short phrase. |
| `.github/workflows/ci-cd.yml` (excerpt) | YAML | Runs `download_kokoro.sh` before the Xcode build on a macOS runner. |
| `package.json` (scripts section) | JSON | Adds shortcut `"download:kokoro": "bash ./scripts/download_kokoro.sh"`. |
---

## üõ†Ô∏è 1Ô∏è‚É£ Shell script ‚Äì `scripts/download_kokoro.sh`
```bash
#!/usr/bin/env bash
# ------------------------------------------------------------
# download_kokoro.sh
#   ‚Ä¢ Clones the MLX‚Äëready Kokoro‚Äë82M checkpoint from Hugging Face.
#   ‚Ä¢ Requires git‚Äëlfs (the model files are stored with LFS).
#   ‚Ä¢ Places the files into ios/KokoroTTS/Resources/
# ------------------------------------------------------------

set -euo pipefail

# Repository to clone (public HF repo)
REPO_URL="https://huggingface.co/mlx-community/Kokoro-82M-bf16"

# Destination inside the project
DEST_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../ios/KokoroTTS/Resources" && pwd)"

mkdir -p "$DEST_DIR"

# If the repo already exists, just pull latest LFS objects.
if [ -d "$DEST_DIR/.git" ]; then
  echo "üîÅ Repo already cloned ‚Äì pulling latest LFS assets‚Ä¶"
  git -C "$DEST_DIR" pull
else
  echo "üì• Cloning Kokoro model repository (LFS)‚Ä¶"
  git clone "$REPO_URL" "$DEST_DIR"
fi

# Verify the expected files are present
if [[ -f "$DEST_DIR/kokoro.mlx" && -f "$DEST_DIR/tokenizer.json" ]]; then
  echo "‚úÖ Model and tokenizer are ready in $DEST_DIR"
else
  echo "‚ùå Expected files not found ‚Äì ensure git‚Äëlfs is installed"
  exit 1
fi
```
*Make executable:* `chmod +x scripts/download_kokoro.sh`.
*Dependencies:* `git` (built‚Äëin) and `git-lfs` (`brew install git-lfs && git lfs install`). All macOS CI runners already have Git‚ÄØLFS.
---

## üßë‚Äçüíª 2Ô∏è‚É£ Swift side ‚Äì `ios/KokoroTTS/`
**`KokoroTTSModule.swift`** (Expo bridge)
```swift
import ExpoModulesCore
import AVFoundation
import Foundation

public class KokoroTTSModule: Module {
  public func definition() -> ModuleDefinition {
    Name("KokoroTTS")
    Function("synthesize") { (text: String, voice: String, resolver: PromiseResolveBlock, rejecter: PromiseRejectBlock) in
      Task {
        do {
          let url = try await KokoroInference.shared.synthesize(text: text, voice: voice)
          resolver(url.absoluteString)
        } catch {
          rejecter("E_TTS_FAILED", "Synthesis failed: \(error)", error)
        }
      }
    }
  }
}
```
**`KokoroInference.swift`** (core inference)
```swift
import Foundation
import MLX
import MLXNN
import AVFoundation

final class KokoroInference {
  static let shared = KokoroInference()
  private let model: MLXModel
  private let tokenizer: [String: [Int]]

  private init() throws {
    // Load the .mlx checkpoint bundled in Resources
    guard let modelURL = Bundle.module.url(forResource: "kokoro", withExtension: "mlx") else {
      fatalError("‚ùå kokoro.mlx not found in bundle")
    }
    self.model = try MLXModel(contentsOf: modelURL)

    // Load tokenizer JSON (simple char‚Üítoken map)
    guard let tokenURL = Bundle.module.url(forResource: "tokenizer", withExtension: "json") else {
      fatalError("‚ùå tokenizer.json not found in bundle")
    }
    let data = try Data(contentsOf: tokenURL)
    self.tokenizer = try JSONSerialization.jsonObject(with: data) as! [String: [Int]]
  }

  /// Public entry point used by the bridge
  func synthesize(text: String, voice: String) async throws -> URL {
    let tokenIds = tokenize(text)
    var input = mx.array(tokenIds, dtype: .int32).expandDims(0) // [1, seq]
    let voiceId = voiceID(for: voice)
    // Forward pass ‚Äì the checkpoint expects "input" + "voice" keys
    let output = try model.forward(dict: ["input": input, "voice": mx.array([voiceId])])
    guard let audioBF16 = output["audio"] else { fatalError("No audio output") }
    // Cast BF16 ‚Üí Float32 for AVAudio
    let audioF32 = audioBF16.astype(.float32).flattened()
    let wavURL = try writeWavFile(samples: audioF32)
    return wavURL
  }

  // -------------------------------------------------
  private func tokenize(_ text: String) -> [Int] {
    var ids: [Int] = []
    for ch in text {
      if let toks = tokenizer[String(ch)] { ids.append(contentsOf: toks) }
    }
    ids.append(0) // EOS token
    return ids
  }

  private func voiceID(for name: String) -> Int {
    // Mapping taken from the model‚Äôs README (adjust if needed)
    let map = ["af_heart": 0, "af_talk": 1, "en_us_heart": 2, "en_us_talk": 3]
    return map[name] ?? 2
  }

  private func writeWavFile(samples: MLXArray) throws -> URL {
    // Convert MLXArray ‚Üí Swift [Float]
    let floats = samples.toArray() as! [Float]
    let sampleRate: Double = 24_000
    let format = AVAudioFormat(standardFormatWithSampleRate: sampleRate, channels: 1)!
    let tempURL = FileManager.default.temporaryDirectory
      .appendingPathComponent(UUID().uuidString).appendingPathExtension("wav")
    let file = try AVAudioFile(forWriting: tempURL, settings: format.settings)
    let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: AVAudioFrameCount(floats.count))!
    buffer.frameLength = buffer.frameCapacity
    floats.withUnsafeBytes { ptr in
      let src = ptr.bindMemory(to: Float.self).baseAddress!
      memcpy(buffer.floatChannelData![0], src, floats.count * MemoryLayout<Float>.size)
    }
    try file.write(from: buffer)
    return tempURL
  }
}
```
*The Swift files are added to a new Xcode target named **KokoroTTS** and linked with the **MLX‚ÄëSwift** package (add via Xcode ‚Üí ‚ÄúAdd Packages‚Ä¶ ‚Üí https://github.com/ml-explore/mlx‚Äëswift.git‚Äù).* 
---

## üßë‚Äçüíª 3Ô∏è‚É£ TypeScript provider
```ts
// services/ai/providers/kokoro.ts
import { NativeModules } from 'react-native';
const { KokoroTTS } = NativeModules;

export const kokoroProvider = {
  /**
   * Calls the native MLX inference and returns a `file://` URL that points to a temporary WAV.
   */
  async synthesize(text: string, voice: string): Promise<string> {
    const url = await KokoroTTS.synthesize(text, voice);
    return url; // e.g. "file:///var/.../tmp/abcd.wav"
  },
};
```
---

## üßë‚Äçüíª 4Ô∏è‚É£ Hook integration
```ts
// hooks/use-text-to-speech.ts
export enum TTSProviderType {
  Remote = 'remote',
  LocalKokoro = 'localKokoro',
}

export const getTTSProvider = (type: TTSProviderType) => {
  switch (type) {
    case TTSProviderType.Remote:   return remoteProvider;
    case TTSProviderType.LocalKokoro: return kokoroProvider;
    default: return remoteProvider;
  }
};
```
Usage example (inside any component):
```ts
import { getTTSProvider, TTSProviderType } from '@/hooks/use-text-to-speech';
const provider = getTTSProvider(useOnDeviceTTS ? TTSProviderType.LocalKokoro : TTSProviderType.Remote);
const wavUrl = await provider.synthesize(message, 'en_us_heart');
// Play with expo‚Äëav or your existing audio player
```
---

## üñ•Ô∏è 5Ô∏è‚É£ Settings UI (optional toggle)
```tsx
// components/settings-view.tsx (excerpt)
import { Switch, Platform, View, Text } from 'react-native';
import { useSettingsStore } from '@/stores/use-settings-store';

export const SettingsView = () => {
  const { useOnDeviceTTS, setUseOnDeviceTTS } = useSettingsStore();

  return (
    <View>
      {/* other rows ‚Ä¶ */}
      {Platform.OS === 'ios' && (
        <View style={{ flexDirection: 'row', alignItems: 'center', marginVertical: 8 }}>
          <Text style={{ flex: 1 }}>Use on‚Äëdevice speech (Kokoro)</Text>
          <Switch value={useOnDeviceTTS} onValueChange={setUseOnDeviceTTS} />
        </View>
      )}
    </View>
  );
};
```
Persist `useOnDeviceTTS` in the existing `use-settings-store.ts` (e.g., via `AsyncStorage`).
---

## üß™ 6Ô∏è‚É£ Tests
### Unit test (mocked native module)
```tsx
// tests/unit/components/kokoro-tts.test.tsx
import { kokoroProvider } from '@/services/ai/providers/kokoro';
import { NativeModules } from 'react-native';

jest.mock('react-native', () => ({
  NativeModules: { KokoroTTS: { synthesize: jest.fn().mockResolvedValue('file:///tmp/audio.wav') } },
}));

test('kokoroProvider resolves a file URL', async () => {
  const url = await kokoroProvider.synthesize('Hello', 'en_us_heart');
  expect(url).toBe('file:///tmp/audio.wav');
  expect(NativeModules.KokoroTTS.synthesize).toHaveBeenCalledWith('Hello', 'en_us_heart');
});
```
### E2E test (real iOS simulator)
```tsx
// tests/e2e/kokoro-tts.e2e.test.ts
import { kokoroProvider } from '@/services/ai/providers/kokoro';
import * as FileSystem from 'expo-file-system';
import { Audio } from 'expo-av';

test('real synthesis produces a playable wav', async () => {
  const url = await kokoroProvider.synthesize('Test phrase', 'en_us_heart');
  const info = await FileSystem.getInfoAsync(url);
  expect(info.exists && info.size > 0).toBe(true);

  const sound = new Audio.Sound();
  await sound.loadAsync({ uri: url });
  await sound.playAsync();
  await new Promise(r => setTimeout(r, 1500)); // let a short clip play
  await sound.unloadAsync();
});
```
Add the test file to the existing `vitest` config (or your Playwright setup) so it runs on the macOS CI runner.
---

## ü§ñ 7Ô∏è‚É£ CI integration (macOS runner)
Excerpt to add to `.github/workflows/ci-cd.yml`:
```yaml
jobs:
  ios-tests:
    runs-on: macos-14   # Apple‚Äësilicon runner
    steps:
      - uses: actions/checkout@v4

      # Ensure git‚Äëlfs is available (pre‚Äëinstalled on macOS runners)
      - name: Install git‚Äëlfs (just in case)
        run: brew install git-lfs && git lfs install

      - name: Download Kokoro model (shell script)
        run: bash ./scripts/download_kokoro.sh

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install npm dependencies
        run: npm ci

      - name: Build iOS app (Xcode)
        run: |
          xcodebuild clean build \
            -workspace ai-dnd-expo.xcworkspace \
            -scheme ai-dnd-expo \
            -configuration Debug \
            -sdk iphonesimulator \
            -destination 'platform=iOS Simulator,name=iPhone 16,OS=latest'

      - name: Run iOS unit & e2e tests
        run: npm run test:e2e   # or whatever command runs the Vitest/Playwright suite
```
The script runs **before** the Xcode build, guaranteeing the model files are present in the bundle.
---

## üì¶ 8Ô∏è‚É£ Convenience npm script
Add to `package.json`:
```json
"scripts": {
  "download:kokoro": "bash ./scripts/download_kokoro.sh",
  // ‚Ä¶other scripts
}
```
Now developers can simply run `npm run download:kokoro` to fetch the checkpoint without touching Python.
---

## üéâ Result
When the toggle is on (iOS only), the app will synthesize speech **entirely on the device** using the lightweight Kokoro‚Äë82M model, eliminating network latency and API costs. The implementation stays fully type‚Äësafe, test‚Äëcovered, and CI‚Äëverified.
---

*All paths are relative to the repository root. The Markdown file itself can be opened for the exact commands and code snippets.*