/**
 * Gemma3 Tokenizer for Local AI D&D Platform
 *
 * Handles tokenization and detokenization for Gemma3 models with D&D-specific
 * prompt formatting and special token handling.
 *
 * Requirements: 2.1, 2.2
 */

export interface TokenizerConfig {
  vocabSize: number;
  bosToken: string;
  eosToken: string;
  unkToken: string;
  padToken: string;
  specialTokens: Record<string, number>;
  maxSequenceLength: number;
}

export interface TokenizationResult {
  inputIds: number[];
  attentionMask: number[];
  positionIds?: number[];
  tokenCount: number;
}

export interface DetokenizationResult {
  text: string;
  specialTokensFound: string[];
  truncated: boolean;
}

export interface DnDPromptContext {
  playerName: string;
  playerClass: string;
  playerRace: string;
  currentScene: string;
  gameHistory: string[];
  systemPrompt?: string;
}

/**
 * Gemma3 Tokenizer for D&D applications
 * Handles tokenization with D&D-specific prompt formatting
 */
export class Gemma3Tokenizer {
	private config: TokenizerConfig;
	private vocabMap: Map<string, number> = new Map();
	private reverseVocabMap: Map<number, string> = new Map();
	private isInitialized = false;

	constructor(config?: Partial<TokenizerConfig>) {
		this.config = {
			vocabSize: 32000,
			bosToken: '<bos>',
			eosToken: '<eos>',
			unkToken: '<unk>',
			padToken: '<pad>',
			specialTokens: {
				'<bos>': 1,
				'<eos>': 2,
				'<unk>': 3,
				'<pad>': 0,
				'<start_of_turn>': 106,
				'<end_of_turn>': 107,
				'<start_of_dm>': 108, // Custom D&D token
				'<end_of_dm>': 109,   // Custom D&D token
			},
			maxSequenceLength: 2048,
			...config,
		};
	}

	/**
   * Initialize tokenizer with vocabulary
   * In a real implementation, this would load from a tokenizer.json file
   */
	async initialize(): Promise<void> {
		try {
			console.log('üî§ Initializing Gemma3 tokenizer...');

			// Initialize special tokens
			for (const [token, id] of Object.entries(this.config.specialTokens)) {
				this.vocabMap.set(token, id);
				this.reverseVocabMap.set(id, token);
			}

			// In a real implementation, we would load the full vocabulary
			// For now, we'll create a basic vocabulary for common words
			await this.initializeBasicVocabulary();

			this.isInitialized = true;
			console.log('‚úÖ Gemma3 tokenizer initialized');

		} catch (error) {
			console.error('‚ùå Failed to initialize tokenizer:', error);
			throw new Error(`Tokenizer initialization failed: ${error}`);
		}
	}

	/**
   * Tokenize text with D&D-specific formatting
   * Requirement 2.1: D&D-specific prompt formatting
   */
	async tokenize(text: string, context?: DnDPromptContext): Promise<TokenizationResult> {
		if (!this.isInitialized) {
			await this.initialize();
		}

		try {
			// Format text with D&D context if provided
			const formattedText = context ? this.formatDnDPrompt(text, context) : text;

			// Basic tokenization (in a real implementation, this would use SentencePiece)
			const tokens = this.basicTokenize(formattedText);

			// Add special tokens
			const inputIds = [
				this.config.specialTokens['<bos>'],
				...tokens,
				this.config.specialTokens['<eos>'],
			];

			// Create attention mask (1 for real tokens, 0 for padding)
			const attentionMask = new Array(inputIds.length).fill(1);

			// Create position IDs
			const positionIds = Array.from({ length: inputIds.length }, (_, i) => i);

			// Truncate if too long
			if (inputIds.length > this.config.maxSequenceLength) {
				inputIds.splice(this.config.maxSequenceLength);
				attentionMask.splice(this.config.maxSequenceLength);
				positionIds.splice(this.config.maxSequenceLength);

				// Ensure we end with EOS token
				inputIds[inputIds.length - 1] = this.config.specialTokens['<eos>'];
			}

			return {
				inputIds,
				attentionMask,
				positionIds,
				tokenCount: inputIds.length,
			};

		} catch (error) {
			console.error('‚ùå Tokenization failed:', error);
			throw new Error(`Tokenization failed: ${error}`);
		}
	}

	/**
   * Detokenize token IDs back to text
   * Requirement 2.2: Proper output handling
   */
	async detokenize(tokenIds: number[]): Promise<DetokenizationResult> {
		if (!this.isInitialized) {
			await this.initialize();
		}

		try {
			const tokens: string[] = [];
			const specialTokensFound: string[] = [];
			const truncated = false;

			for (const tokenId of tokenIds) {
				const token = this.reverseVocabMap.get(tokenId);

				if (token) {
					// Check if it's a special token
					if (Object.values(this.config.specialTokens).includes(tokenId)) {
						specialTokensFound.push(token);

						// Skip certain special tokens in output
						if (!['<bos>', '<eos>', '<pad>'].includes(token)) {
							tokens.push(token);
						}
					} else {
						tokens.push(token);
					}
				} else {
					// Unknown token, use UNK
					tokens.push(this.config.unkToken);
				}
			}

			// Join tokens and clean up
			let text = tokens.join(' ');
			text = this.postProcessText(text);

			return {
				text,
				specialTokensFound,
				truncated,
			};

		} catch (error) {
			console.error('‚ùå Detokenization failed:', error);
			throw new Error(`Detokenization failed: ${error}`);
		}
	}

	/**
   * Format D&D-specific prompt with context
   * Requirement 2.1: D&D-specific prompt formatting
   */
	private formatDnDPrompt(userInput: string, context: DnDPromptContext): string {
		const systemPrompt = context.systemPrompt || this.getDefaultDnDSystemPrompt();

		let prompt = `${systemPrompt}\n\n`;

		// Add character context
		prompt += '<start_of_turn>user\n';
		prompt += `Character: ${context.playerName} (${context.playerRace} ${context.playerClass})\n`;
		prompt += `Location: ${context.currentScene}\n`;

		// Add recent game history for context
		if (context.gameHistory.length > 0) {
			const recentHistory = context.gameHistory.slice(-3).join(' ');
			prompt += `Recent events: ${recentHistory}\n`;
		}

		prompt += `Action: ${userInput}\n`;
		prompt += '<end_of_turn>\n';

		// Start DM response
		prompt += '<start_of_turn>model\n<start_of_dm>\n';

		return prompt;
	}

	/**
   * Get default D&D system prompt for Gemma3
   */
	private getDefaultDnDSystemPrompt(): string {
		return `You are an experienced Dungeon Master running a D&D 5e campaign. Your role is to:

1. Create engaging, immersive narratives that respond to player actions
2. Follow D&D 5e rules accurately for combat, skill checks, and magic
3. Generate appropriate dice roll commands using [ROLL:XdY+Z] format
4. Maintain story consistency and character development
5. Keep responses concise (1-3 sentences) but descriptive
6. Create challenging but fair encounters
7. Encourage creative problem-solving

Response format:
- Describe the scene and consequences of the player's action
- Include dice rolls when appropriate: [ROLL:1d20+modifier]
- Use character updates when needed: [UPDATE:HP-5] or [UPDATE:XP+100]
- End with a question or prompt for the next action

Always stay in character as the DM and maintain the fantasy atmosphere.`;
	}

	/**
   * Basic tokenization (simplified version)
   * In a real implementation, this would use SentencePiece or similar
   */
	private basicTokenize(text: string): number[] {
		// Simple word-based tokenization for demonstration
		// Real implementation would use subword tokenization
		const words = text.toLowerCase()
			.replace(/[^\w\s<>]/g, ' ')
			.split(/\s+/)
			.filter(word => word.length > 0);

		const tokens: number[] = [];

		for (const word of words) {
			// Check if it's a special token
			if (this.vocabMap.has(word)) {
				tokens.push(this.vocabMap.get(word)!);
			} else {
				// Simple hash-based token ID generation (not production-ready)
				const tokenId = this.simpleHash(word) % (this.config.vocabSize - 1000) + 1000;
				tokens.push(tokenId);
			}
		}

		return tokens;
	}

	/**
   * Initialize basic vocabulary for common words
   */
	private async initializeBasicVocabulary(): Promise<void> {
		// Common D&D and English words
		const commonWords = [
			'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
			'you', 'your', 'i', 'me', 'my', 'we', 'us', 'our', 'they', 'them', 'their', 'he', 'him', 'his', 'she', 'her',
			'attack', 'hit', 'damage', 'roll', 'dice', 'check', 'save', 'spell', 'cast', 'move', 'go', 'look', 'search',
			'sword', 'shield', 'armor', 'bow', 'arrow', 'magic', 'potion', 'gold', 'treasure', 'door', 'room', 'dungeon',
			'dragon', 'goblin', 'orc', 'skeleton', 'zombie', 'wizard', 'fighter', 'rogue', 'cleric', 'barbarian',
			'strength', 'dexterity', 'constitution', 'intelligence', 'wisdom', 'charisma', 'hp', 'health', 'mana',
		];

		let tokenId = 100; // Start after special tokens
		for (const word of commonWords) {
			if (!this.vocabMap.has(word)) {
				this.vocabMap.set(word, tokenId);
				this.reverseVocabMap.set(tokenId, word);
				tokenId++;
			}
		}
	}

	/**
   * Simple hash function for generating token IDs
   */
	private simpleHash(str: string): number {
		let hash = 0;
		for (let i = 0; i < str.length; i++) {
			const char = str.charCodeAt(i);
			hash = ((hash << 5) - hash) + char;
			hash = hash & hash; // Convert to 32-bit integer
		}
		return Math.abs(hash);
	}

	/**
   * Post-process detokenized text
   */
	private postProcessText(text: string): string {
		return text
			.replace(/\s+/g, ' ') // Normalize whitespace
			.replace(/\s+([.,!?;:])/g, '$1') // Remove space before punctuation
			.replace(/\(\s+/g, '(') // Remove space after opening parenthesis
			.replace(/\s+\)/g, ')') // Remove space before closing parenthesis
			.trim();
	}

	/**
   * Get tokenizer configuration
   */
	getConfig(): TokenizerConfig {
		return { ...this.config };
	}

	/**
   * Check if tokenizer is ready
   */
	isReady(): boolean {
		return this.isInitialized;
	}

	/**
   * Get vocabulary size
   */
	getVocabSize(): number {
		return this.config.vocabSize;
	}

	/**
   * Get special token ID
   */
	getSpecialTokenId(token: string): number | undefined {
		return this.config.specialTokens[token];
	}

	/**
   * Encode special D&D commands in text
   */
	encodeDnDCommands(text: string): string {
		// Replace D&D tool commands with special tokens for better model understanding
		return text
			.replace(/\[ROLL:([^\]]+)\]/g, '<roll>$1</roll>')
			.replace(/\[UPDATE:([^\]]+)\]/g, '<update>$1</update>')
			.replace(/\[DAMAGE:([^\]]+)\]/g, '<damage>$1</damage>')
			.replace(/\[HEAL:([^\]]+)\]/g, '<heal>$1</heal>');
	}

	/**
   * Decode special D&D commands from text
   */
	decodeDnDCommands(text: string): string {
		// Convert special tokens back to D&D tool commands
		return text
			.replace(/<roll>([^<]+)<\/roll>/g, '[ROLL:$1]')
			.replace(/<update>([^<]+)<\/update>/g, '[UPDATE:$1]')
			.replace(/<damage>([^<]+)<\/damage>/g, '[DAMAGE:$1]')
			.replace(/<heal>([^<]+)<\/heal>/g, '[HEAL:$1]');
	}
}

/**
 * Utility functions for Gemma3 tokenization
 */
export const Gemma3TokenizerUtils = {
	/**
   * Estimate token count for text (rough approximation)
   */
	estimateTokenCount(text: string): number {
		// Rough estimation: ~4 characters per token for English text
		return Math.ceil(text.length / 4);
	},

	/**
   * Truncate text to fit within token limit
   */
	truncateToTokenLimit(text: string, maxTokens: number): string {
		const estimatedTokens = Gemma3TokenizerUtils.estimateTokenCount(text);

		if (estimatedTokens <= maxTokens) {
			return text;
		}

		// Rough truncation based on character count
		const maxChars = maxTokens * 4;
		return text.substring(0, maxChars - 3) + '...';
	},

	/**
   * Validate D&D prompt format
   */
	validateDnDPrompt(prompt: string): {
    valid: boolean;
    issues: string[];
    suggestions: string[];
  } {
		const issues: string[] = [];
		const suggestions: string[] = [];

		// Check for required D&D context
		if (!prompt.includes('Character:')) {
			issues.push('Missing character information');
			suggestions.push('Include character name, race, and class');
		}

		if (!prompt.includes('Location:') && !prompt.includes('Scene:')) {
			issues.push('Missing location/scene context');
			suggestions.push('Include current location or scene description');
		}

		// Check prompt length
		if (prompt.length < 50) {
			issues.push('Prompt too short for meaningful context');
			suggestions.push('Provide more detail about the action or situation');
		}

		if (prompt.length > 2000) {
			issues.push('Prompt too long, may exceed token limits');
			suggestions.push('Condense the prompt to focus on key information');
		}

		return {
			valid: issues.length === 0,
			issues,
			suggestions,
		};
	},

	/**
   * Extract D&D commands from tokenized output
   */
	extractDnDCommands(text: string): Array<{
    type: 'roll' | 'update' | 'damage' | 'heal' | 'status';
    params: string;
    position: number;
  }> {
		const commands: Array<{
      type: 'roll' | 'update' | 'damage' | 'heal' | 'status';
      params: string;
      position: number;
    }> = [];

		const patterns = [
			{ type: 'roll' as const, regex: /\[ROLL:([^\]]+)\]/g },
			{ type: 'update' as const, regex: /\[UPDATE:([^\]]+)\]/g },
			{ type: 'damage' as const, regex: /\[DAMAGE:([^\]]+)\]/g },
			{ type: 'heal' as const, regex: /\[HEAL:([^\]]+)\]/g },
			{ type: 'status' as const, regex: /\[STATUS:([^\]]+)\]/g },
		];

		for (const pattern of patterns) {
			let match;
			while ((match = pattern.regex.exec(text)) !== null) {
				commands.push({
					type: pattern.type,
					params: match[1],
					position: match.index,
				});
			}
		}

		// Sort by position in text
		return commands.sort((a, b) => a.position - b.position);
	},
};

/**
 * Default tokenizer configuration for Gemma3
 */
export const DefaultGemma3TokenizerConfig: TokenizerConfig = {
	vocabSize: 32000,
	bosToken: '<bos>',
	eosToken: '<eos>',
	unkToken: '<unk>',
	padToken: '<pad>',
	specialTokens: {
		'<bos>': 1,
		'<eos>': 2,
		'<unk>': 3,
		'<pad>': 0,
		'<start_of_turn>': 106,
		'<end_of_turn>': 107,
		'<start_of_dm>': 108,
		'<end_of_dm>': 109,
	},
	maxSequenceLength: 2048,
};
